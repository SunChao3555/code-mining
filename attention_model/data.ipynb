{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tokenize import generate_tokens\n",
    "from cStringIO import StringIO\n",
    "from collections import defaultdict\n",
    "import ast\n",
    "import astor\n",
    "from py2_tokenize import tokenize_code\n",
    "import numpy as np\n",
    "from scipy.stats.mstats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_contiguous_snippets(code_snippet):\n",
    "    try:\n",
    "        tokens = [token for _, token, _, _, _  in generate_tokens(StringIO(code_snippet).readline) if token]\n",
    "    except:\n",
    "        return []\n",
    "    sub_snippet_set = set()\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(i+1, len(tokens)+1):\n",
    "            con_tokens = tokens[i:j]\n",
    "            if con_tokens[-1] == ':':\n",
    "                con_tokens.append('pass')\n",
    "            sub_snippet = ' '.join(con_tokens)\n",
    "            try:\n",
    "                root = ast.parse(sub_snippet)\n",
    "                cc = astor.to_source(root)\n",
    "                tokenize_code(cc.encode('utf-8'))\n",
    "                sub_snippet_set.add(cc)\n",
    "            except:\n",
    "                pass\n",
    "    return sub_snippet_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotations = pickle.load(open('annotations.p', 'rb'))\n",
    "questions = pickle.load(open('questions.p', 'rb'))\n",
    "candidates = pickle.load(open('candidates.p', 'rb'))\n",
    "intents = pickle.load(open('intents.p', 'rb'))\n",
    "baseline = pickle.load(open('baseline.p', 'rb'))\n",
    "bi_likelihood = pickle.load(open('bi_likelihood.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {}\n",
    "for post_id, q in questions.items():\n",
    "    intent = intents[post_id]\n",
    "    features[post_id] = []\n",
    "    for s in q['snippet']:\n",
    "        abs_likelihood = {c: bi_likelihood[post_id][c] for c in sub_contiguous_snippets(s)}.items()\n",
    "        if len(abs_likelihood) <= 1:\n",
    "            continue\n",
    "        c, ff = zip(*abs_likelihood)\n",
    "        ff = np.hstack([np.array(ff), zscore(np.array(ff), axis=0)])\n",
    "        features[post_id].extend(zip(c, ff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat(context, snippet):\n",
    "    return astor.to_source(ast.parse(context + '\\n' + snippet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_pos = defaultdict(set)\n",
    "snippet_pos = defaultdict(set)\n",
    "full_pos = defaultdict(set)\n",
    "for a in annotations:\n",
    "    post_id = a['post_id']\n",
    "    if a['context_ref'] in candidates[post_id]:\n",
    "        context_pos[post_id].add(a['context_ref'])\n",
    "    if a['snippet_ref'] in candidates[post_id]:\n",
    "        snippet_pos[post_id].add(a['snippet_ref'])\n",
    "    if a['snippet_ref'] == '':\n",
    "        print a\n",
    "    try:\n",
    "        full = concat(a['context_ref'], a['snippet_ref'])\n",
    "        if full in candidates[post_id]:\n",
    "            full_pos[post_id].add(full)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_x_y(pos_set):\n",
    "    x = []\n",
    "    y = []\n",
    "    for post_id in features:\n",
    "        for c, ff in features[post_id]:\n",
    "            x.append(ff)\n",
    "            y.append(c in pos_set[post_id])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "snippet_x, snippet_y = generate_x_y(snippet_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context_x, context_y = generate_x_y(context_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_x, full_y = generate_x_y(full_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
