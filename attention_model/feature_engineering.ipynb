{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import ast\n",
    "from astor import to_source\n",
    "from tokenize import generate_tokens\n",
    "from cStringIO import StringIO\n",
    "from random import shuffle\n",
    "from py2_tokenize import tokenize_code\n",
    "from _ast import ImportFrom, Assign, Expr, Name, Num, Str, Print, Return\n",
    "from HTMLParser import HTMLParser\n",
    "from sklearn import preprocessing\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "annotations = pickle.load(open('annotations.p', 'rb'))\n",
    "questions = pickle.load(open('questions.p', 'rb'))\n",
    "titles = pickle.load(open('titles.p', 'rb'))\n",
    "posts = pickle.load(open('posts.p', 'rb'))\n",
    "baseline = pickle.load(open('baseline.p', 'rb'))\n",
    "intents = {post_id: q['intent'] for post_id, q in questions.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if the code snippet was copied from an python REPL\n",
    "def from_console(code, prompts=[' >>>', '  >>> ', '>>> ', '... ', '$ ']):\n",
    "    for line in code.split('\\n'):\n",
    "        for p in prompts:\n",
    "            if line.startswith(p):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove prompt prefixes from code\n",
    "def console_extract(code, prompts=[' >>>', '  >>> ', '>>> ', '... ', '$ ']):\n",
    "    lines = []\n",
    "    for line in code.split('\\n'):\n",
    "        for p in prompts:\n",
    "            if line.startswith(p):\n",
    "                lines.append(line[len(p):])\n",
    "                break\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if the code snippet was copied from an ipython REPL\n",
    "def from_ipython(code, patterns=[re.compile(r'In \\[\\d+\\]: '), re.compile(r'In \\[\\d+\\]:')]):\n",
    "    for line in code.split('\\n'):\n",
    "        for p in patterns:\n",
    "            match = p.match(line)\n",
    "            if match:\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove ipython prompt prefixes from code\n",
    "def ipython_extract(code, patterns=[re.compile(r'In \\[\\d+\\]: '), re.compile(r'   \\.\\.\\.\\: '), re.compile(r'In \\[\\d+\\]:'), re.compile(r'   \\.\\.\\.\\:')]):\n",
    "    lines = []\n",
    "    for line in code.split('\\n'):\n",
    "        for p in patterns:\n",
    "            match = p.match(line)\n",
    "            if match:\n",
    "                lines.append(line[match.end():])\n",
    "                break\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove comments from code\n",
    "def remove_comment(code):\n",
    "    lines = code.split('\\n')\n",
    "    for i, line in enumerate(lines):\n",
    "        try:\n",
    "            for toknum, tokval, (_, start), _, _  in generate_tokens(StringIO(line).readline):\n",
    "                if toknum == 53:\n",
    "                    lines[i] = line[:start]\n",
    "        except:\n",
    "            pass\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove unnecessary indents from code, for example:\n",
    "\"\"\"\n",
    "    if a == b:\n",
    "        print a\n",
    "\"\"\"\n",
    "# =>\n",
    "\"\"\"\n",
    "if a == b:\n",
    "    print a\n",
    "\"\"\"\n",
    "def remove_indents(code):\n",
    "    lines = [line for line in code.split('\\n') if line.strip()]\n",
    "    if not lines:\n",
    "        return code\n",
    "    indent_length, example = min((len(line) - len(line.lstrip()), line) for line in lines)\n",
    "    indent = example[:indent_length]\n",
    "    for i, line in enumerate(lines):\n",
    "        if not line.startswith(indent):\n",
    "            return code\n",
    "        lines[i] = line[indent_length:]\n",
    "    return '\\n'.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add pass statement to complete for partial-snippet (e.g. if statement without then branch)\n",
    "def add_pass(code):\n",
    "    striped_code = code.rstrip()\n",
    "    if striped_code and striped_code[-1] == ':':\n",
    "        return striped_code + 'pass'\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize the code-snippet for exactly match\n",
    "def normalize_code(code, pid=None):\n",
    "    old_code = code\n",
    "    if from_console(code):\n",
    "        code = console_extract(code)\n",
    "    elif from_ipython(code):\n",
    "        code = ipython_extract(code)\n",
    "    code = remove_comment(code)\n",
    "    code = remove_indents(code)\n",
    "    code = add_pass(code)\n",
    "    add_future = False\n",
    "    # hack: parse python3-style print statement\n",
    "    if 'print(' in code and 'print_function' not in code:\n",
    "        code = 'from __future__ import print_function\\n' + code\n",
    "        add_future = True\n",
    "    try:\n",
    "        result = to_source(ast.parse(code))\n",
    "        if add_future:\n",
    "            result = '\\n'.join(result.split('\\n')[1:])\n",
    "        return result\n",
    "    except Exception as ex:\n",
    "        if pid is not None:\n",
    "            print pid\n",
    "            print '--------------------'\n",
    "        print old_code\n",
    "        print '--------------------'\n",
    "        print code\n",
    "        print '--------------------'\n",
    "        print type(ex)\n",
    "        print ex\n",
    "        print '===================='\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalized_annotation = []\n",
    "for a in annotations:\n",
    "    if a['post_id'] in (952914, 9542738, 38987, 6213336):\n",
    "        continue\n",
    "    normalized_annotation.append({\n",
    "        'post_id': a['post_id'],\n",
    "        'intent_ref': a['intent_ref'].strip(),\n",
    "        'context_ref': normalize_code(a['context_ref'], a['post_id']),\n",
    "        'snippet_ref': normalize_code(a['snippet_ref'], a['post_id']),\n",
    "        'intent_text': a['intent_text'],\n",
    "        'context_text': a['context_text'],\n",
    "        'snippet_text': a['snippet_text'],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(normalized_annotation, open('normalized_annotation.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get ground truth for \"snippet\" annotation\n",
    "snippet_pos = defaultdict(set)\n",
    "for a in normalized_annotation:\n",
    "    post_id = a['post_id']\n",
    "    if a['snippet_ref'] in snippet_pos[post_id]:\n",
    "        #print a\n",
    "        #print snippet_pos[post_id]\n",
    "        pass\n",
    "    else:\n",
    "        snippet_pos[post_id].add(a['snippet_ref'])\n",
    "pickle.dump(snippet_pos, open('snippet_pos.p', 'wb'))\n",
    "sum(map(len, snippet_pos.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, f1_score, recall_score, precision_score, precision_recall_curve\n",
    "from scipy.stats.mstats import zscore\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#unescape the html context (e.g. &amp => &)\n",
    "def unescape(text, parser=HTMLParser()):\n",
    "    return parser.unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get all the code snippet form a html context (extracting all the sub-text inside <code> tags)\n",
    "#for future snippet-candidates generation \n",
    "def get_code_list(html_list, is_code=True):\n",
    "    for html in html_list:\n",
    "        for start, end in get_code_spans(html, is_code):\n",
    "            yield unescape(html[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get char-based offsets i.e (start_of_code_snippet, end_of_code_snippet) for all\n",
    "#the code snippets inside a html body (post content)\n",
    "def get_code_span(html, match):\n",
    "    start, end = match.span()\n",
    "    code = match.group(1)\n",
    "    start += html[start:end].find(code)\n",
    "    end = start + len(code)\n",
    "    return (start, end)\n",
    "\n",
    "def get_code_spans(html, is_code):\n",
    "    if not is_code:\n",
    "        return [(0, len(html))]\n",
    "    matches = re.finditer(r\"<pre[^>]*>[^<]*<code[^>]*>((?:\\s|[^<]|<span[^>]*>[^<]+</span>)*)</code></pre>\", html)\n",
    "    return [get_code_span(html, m) for m in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#is a literal value (e.g. True \"test\" 3.14)\n",
    "def only_value(root):\n",
    "    if root is None or not hasattr(root, 'body'):\n",
    "        return False\n",
    "    if len(root.body) != 1:\n",
    "        return False\n",
    "    exp = root.body[0]\n",
    "    if not isinstance(exp, Expr):\n",
    "        return False\n",
    "    if isinstance(exp.value, (Name, Num, Str)):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#starts with a assign statement\n",
    "def start_with_assign(root):\n",
    "    if root is None or not hasattr(root, 'body'):\n",
    "        return False\n",
    "    for s in root.body:\n",
    "        if isinstance(s, ImportFrom):\n",
    "            continue\n",
    "        return isinstance(s, Assign)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate all the contiguous sinppet candidates (after normalization)\n",
    "#also generate following features for every candidate:\n",
    "#start_of_line, end_of_line, end_of_block, whole_block, starts_assign, single_value\n",
    "def sub_contiguous_snippets(code_snippet, full_line=True):\n",
    "    try:\n",
    "        tokens = [(token, line_no) for _, token, (line_no, _), _, _  in generate_tokens(StringIO(code_snippet).readline) if token]\n",
    "    except:\n",
    "        return []\n",
    "    sub_snippet_set = set()\n",
    "    for i in range(len(tokens)):\n",
    "        start_of_line = i == 0 or tokens[i-1][1] != tokens[i][1]\n",
    "        if full_line and not start_of_line:\n",
    "            continue\n",
    "        for j in range(i+1, len(tokens)+1):\n",
    "            end_of_line = j == len(tokens) or tokens[j-1][1] != tokens[j][1]\n",
    "            if full_line and not end_of_line:\n",
    "                continue\n",
    "            end_of_block = j == len(tokens)\n",
    "            whole_block = i == 0 and end_of_block\n",
    "            con_tokens, _ = zip(*tokens[i:j])\n",
    "            cc_tokens = [' ', ]\n",
    "            for t in con_tokens:\n",
    "                if not cc_tokens[-1].isspace():\n",
    "                    cc_tokens.append(' ')\n",
    "                cc_tokens.append(t)\n",
    "            sub_snippet = ''.join(cc_tokens[1:])\n",
    "            sub_snippet = add_pass(remove_indents(sub_snippet))\n",
    "            add_future = False\n",
    "            if 'print (' in sub_snippet and 'print_function' not in sub_snippet:\n",
    "                sub_snippet = 'from __future__ import print_function\\n' + sub_snippet\n",
    "                add_future = True\n",
    "            try:\n",
    "                root = ast.parse(sub_snippet)\n",
    "                starts_assign = start_with_assign(root)\n",
    "                single_value = only_value(root)\n",
    "                cc = to_source(root)\n",
    "                if add_future:\n",
    "                    cc = '\\n'.join(cc.split('\\n')[1:])\n",
    "                if len(cc.strip()) == 0:\n",
    "                    continue\n",
    "                if not full_line:\n",
    "                    sub_snippet_set.add((cc, start_of_line, end_of_line, end_of_block, whole_block, starts_assign, single_value))\n",
    "                else:\n",
    "                    sub_snippet_set.add((cc, start_of_line, end_of_line, end_of_block, whole_block, starts_assign, single_value))\n",
    "            except Exception as ex:\n",
    "                #print sub_snippet\n",
    "                #print ex\n",
    "                #print '--------------'\n",
    "                pass\n",
    "    return sub_snippet_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6515"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate all the snippet candidates\n",
    "candidates = {}\n",
    "for post_id, q in questions.items():\n",
    "    cs = set()\n",
    "    for s in q['snippet']:\n",
    "        cs |= set(map(lambda x:x[0], sub_contiguous_snippets(s, True)))\n",
    "    candidates[post_id] = cs\n",
    "pickle.dump(candidates, open('candidates.p', 'wb'))\n",
    "sum(map(len, candidates.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load bi_likelihood feature for candidates\n",
    "bi_likelihood = pickle.load(open('bi_likelihood.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "#if code-snippet was annotated by user (exactly match with some special case handlers: ignore assign / print / return)\n",
    "def is_annotated(code, an_set):\n",
    "    if code in an_set:\n",
    "        return True\n",
    "    if 'print(' in code and 'print_function' not in code:\n",
    "        root = ast.parse('from __future__ import print_function\\n' + code)\n",
    "        del root.body[0]\n",
    "    else:\n",
    "        root = ast.parse(code)\n",
    "    if len(root.body) == 1:\n",
    "        s = root.body[0]\n",
    "        if isinstance(s, Print):\n",
    "            if len(s.values) == 1:\n",
    "                return to_source(s.values[0]) in an_set\n",
    "        elif isinstance(s, Assign):\n",
    "            return to_source(s.value) in an_set\n",
    "        elif isinstance(s, Return):\n",
    "            return to_source(s.value) in an_set\n",
    "    return False\n",
    "print is_annotated('b = a', set(map(normalize_code, ['a'])))\n",
    "print is_annotated('b = a', set(map(normalize_code, ['b'])))\n",
    "print is_annotated('print a', set(map(normalize_code, ['a'])))\n",
    "print is_annotated('print a', set(map(normalize_code, ['b'])))\n",
    "print is_annotated('return a', set(map(normalize_code, ['a'])))\n",
    "print is_annotated('return a', set(map(normalize_code, ['b'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate float vector feature for every candidate\n",
    "def generate_x_y(post_id, codes, pos_set):\n",
    "    features = []\n",
    "    for ss in codes:\n",
    "        #print ss\n",
    "        try:\n",
    "            raw_likelihood = {(c, s, e, end_block, full_block, assign, one_value): bi_likelihood[post_id][c] for c, s, e, end_block, full_block, assign, one_value in sub_contiguous_snippets(ss, True)}\n",
    "        except Exception as ex:\n",
    "            print '========='\n",
    "            print ss\n",
    "            print post_id\n",
    "            raise ex\n",
    "        if len(raw_likelihood) == 0:\n",
    "            print post_id\n",
    "            print ss\n",
    "            continue\n",
    "        #print raw_likelihood\n",
    "        #print sub_contiguous_snippets(ss)\n",
    "        keys, likelihoods = zip(*raw_likelihood.items())\n",
    "        code, start, end, end_of_blocks, full_blocks, assigns, one_values = zip(*keys)\n",
    "        X = np.hstack([np.array(likelihoods), np.array(zip(end_of_blocks, full_blocks, assigns, one_values))])\n",
    "        features.extend((c, x) for c, x, s, e in zip(code, X, start, end) if s and e and c)\n",
    "    if len(features) == 0:\n",
    "        return [], np.array([]), np.array([])\n",
    "    C, F = zip(*features)\n",
    "    F = np.array(F)\n",
    "    z = zscore(np.array(F)[:,0:2], axis=0)\n",
    "    max_z = np.amax(z, axis=1, keepdims=True)\n",
    "    max_p = np.amax(np.array(F)[:,0:2], axis=1, keepdims=True)\n",
    "    contains_import = np.array([['import ' in c] for c in C])\n",
    "    F = np.hstack([F, max_p, contains_import, z, max_z])\n",
    "    return C, F, np.array([is_annotated(c, pos_set[post_id]) for c in C])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shuffle data set\n",
    "pos_set = snippet_pos\n",
    "if os.path.exists('post_list.p'):\n",
    "    post_list = pickle.load(open('post_list.p', 'rb'))\n",
    "else:\n",
    "    post_list = [(k, questions[k]['snippet']) for k, v in pos_set.items() if v]\n",
    "    shuffle(post_list)\n",
    "    pickle.dump(post_list, open('post_list.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"b = '963spam'\\nb.isdigit()\": (2.1683869795365767, 1.8901930914984808), \"a = '03523'\\na.isdigit()\\nb = '963spam'\\nb.isdigit()\": (2.140578860328311, 1.876832538180881), 'a.isdigit()': (1.9315948486328125, 1.9162491692437067), \"a = '03523'\": (3.4557456970214844, 1.838944329155816), \"a = '03523'\\na.isdigit()\\nb = '963spam'\": (2.7104209899902343, 1.848631329006619), \"a.isdigit()\\nb = '963spam'\": (3.32497822154652, 1.8870247734917536), 'b.isdigit()': (2.3747561318533763, 1.9891690148247614), \"b = '963spam'\": (3.5802902221679687, 1.8586900499131944), \"a.isdigit()\\nb = '963spam'\\nb.isdigit()\": (2.4982764300178077, 1.9142095777723525), \"float('NaN')\": (1.9541209538777669, 1.8561358981662326), \"a = '03523'\\na.isdigit()\": (1.934061050415039, 1.8627276950412326)}\n"
     ]
    }
   ],
   "source": [
    "print bi_likelihood[354038]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949318\n",
      "200 OK\n",
      "\n",
      "6996603\n",
      "shutil.rmtree(path[, ignore_errors[, onerror]])\n",
      "\n",
      "6996603\n",
      "os.unlink(path, *, dir_fd=None)\n",
      "\n",
      "6996603\n",
      "os.remove(path, *, dir_fd=None)\n",
      "\n",
      "6996603\n",
      "os.rmdir(path, *, dir_fd=None)\n",
      "\n",
      "21129020\n",
      "\n",
      "3501382\n",
      "isinstance( <var>, int )\n",
      "\n",
      "3501382\n",
      "isinstance( <var>, ( int, long ) )\n",
      "\n",
      "3294889\n",
      "for k in dict: ...\n",
      "\n",
      "3294889\n",
      "for key in dict.iterkeys(): ...\n",
      "\n",
      "for value in dict.itervalues(): ...\n",
      "\n",
      "for key, value in dict.iteritems(): ...\n",
      "\n",
      "3294889\n",
      "for k in dict.keys(): ...\n",
      "\n",
      "845058\n",
      "mapcount : 0.465599966049\n",
      "simplecount : 0.756399965286\n",
      "bufcount : 0.546800041199\n",
      "opcount : 0.718600034714\n",
      "\n",
      "845058\n",
      "mapcount : 0.471799945831\n",
      "simplecount : 0.634400033951\n",
      "bufcount : 0.468800067902\n",
      "opcount : 0.602999973297\n",
      "\n",
      "379906\n",
      "Command to parse                      isFloat?   Note\n",
      "------------------------------------  --------   --------------------------------\n",
      "print(isfloat(\"\"))                    False      Blank string\n",
      "print(isfloat(\"127\"))                 True       Passed string\n",
      "print(isfloat(True))                  True       Pure sweet Truth\n",
      "print(isfloat(\"True\"))                False      Vile contemptible lie\n",
      "print(isfloat(False))                 True       So false it becomes true\n",
      "print(isfloat(\"123.456\"))             True       Decimal\n",
      "print(isfloat(\"      -127    \"))      True       Spaces trimmed\n",
      "print(isfloat(\"\\t\\n12\\r\\n\"))          True       whitespace ignored\n",
      "print(isfloat(\"NaN\"))                 True       Not a number\n",
      "print(isfloat(\"NaNanananaBATMAN\"))    False      I am Batman\n",
      "print(isfloat(\"-iNF\"))                True       Negative infinity\n",
      "print(isfloat(\"123.E4\"))              True       Exponential notation\n",
      "print(isfloat(\".1\"))                  True       mantissa only\n",
      "print(isfloat(\"1,234\"))               False      Commas gtfo\n",
      "print(isfloat(u'\\x30'))               True       Unicode is fine.\n",
      "print(isfloat(\"NULL\"))                False      Null is not special\n",
      "print(isfloat(0x3fade))               True       Hexidecimal\n",
      "print(isfloat(\"6e7777777777777\"))     True       Shrunk to infinity\n",
      "print(isfloat(\"1.797693e+308\"))       True       This is max value\n",
      "print(isfloat(\"infinity\"))            True       Same as inf\n",
      "print(isfloat(\"infinityandBEYOND\"))   False      Extra characters wreck it\n",
      "print(isfloat(\"12.34.56\"))            False      Only one dot allowed\n",
      "print(isfloat(u'四'))                  False      Japanese '4' is not a float.\n",
      "print(isfloat(\"#56\"))                 False      Pound sign\n",
      "print(isfloat(\"56%\"))                 False      Percent of what?\n",
      "print(isfloat(\"0E0\"))                 True       Exponential, move dot 0 places\n",
      "print(isfloat(0**0))                  True       0___0  Exponentiation\n",
      "print(isfloat(\"-5e-5\"))               True       Raise to a negative number\n",
      "print(isfloat(\"+1e1\"))                True       Plus is OK with exponent\n",
      "print(isfloat(\"+1e1^5\"))              False      Fancy exponent not interpreted\n",
      "print(isfloat(\"+1e1.3\"))              False      No decimals in exponent\n",
      "print(isfloat(\"-+1\"))                 False      Make up your mind\n",
      "print(isfloat(\"(1)\"))                 False      Parenthesis is bad\n",
      "\n",
      "2972212\n",
      "% python -mtimeit  \"l=[]\"\n",
      "10000000 loops, best of 3: 0.0711 usec per loop\n",
      "\n",
      "% python -mtimeit  \"l=list()\"\n",
      "1000000 loops, best of 3: 0.297 usec per loop\n",
      "\n",
      "3207219\n",
      "['/home/adam/file1.txt', '/home/adam/file2.txt', .... ]\n",
      "\n",
      "123198\n",
      "-------------------------------------------------------------------------\n",
      "| Function          |Copies Metadata|Copies Permissions|Can Specify Buffer|\n",
      "-------------------------------------------------------------------------\n",
      "| shutil.copy       |      No       |        Yes       |        No        |\n",
      "-------------------------------------------------------------------------\n",
      "| shutil.copyfile   |      No       |         No       |        No        |\n",
      "-------------------------------------------------------------------------\n",
      "| shutil.copy2      |     Yes       |        Yes       |        No        |\n",
      "-------------------------------------------------------------------------\n",
      "| shutil.copyfileobj|      No       |         No       |       Yes        |\n",
      "-------------------------------------------------------------------------\n",
      "\n",
      "311627\n",
      "    %a  Locale’s abbreviated weekday name.\n",
      "    %A  Locale’s full weekday name.      \n",
      "    %b  Locale’s abbreviated month name.     \n",
      "    %B  Locale’s full month name.\n",
      "    %c  Locale’s appropriate date and time representation.   \n",
      "    %d  Day of the month as a decimal number [01,31].    \n",
      "    %f  Microsecond as a decimal number [0,999999], zero-padded on the left\n",
      "    %H  Hour (24-hour clock) as a decimal number [00,23].    \n",
      "    %I  Hour (12-hour clock) as a decimal number [01,12].    \n",
      "    %j  Day of the year as a decimal number [001,366].   \n",
      "    %m  Month as a decimal number [01,12].   \n",
      "    %M  Minute as a decimal number [00,59].      \n",
      "    %p  Locale’s equivalent of either AM or PM.\n",
      "    %S  Second as a decimal number [00,61].\n",
      "    %U  Week number of the year (Sunday as the first day of the week)\n",
      "    %w  Weekday as a decimal number [0(Sunday),6].   \n",
      "    %W  Week number of the year (Monday as the first day of the week)\n",
      "    %x  Locale’s appropriate date representation.    \n",
      "    %X  Locale’s appropriate time representation.    \n",
      "    %y  Year without century as a decimal number [00,99].    \n",
      "    %Y  Year with century as a decimal number.   \n",
      "    %z  UTC offset in the form +HHMM or -HHMM.\n",
      "    %Z  Time zone name (empty string if the object is naive).    \n",
      "    %%  A literal '%' character.\n",
      "\n",
      "311627\n",
      "    Time in seconds since the epoch:    1349271346.46\n",
      "    Current date and time:              2012-10-03 15:35:46.461491\n",
      "    Or like this:                       12-10-03-15-35\n",
      "    Current year:                       2012\n",
      "    Month of year:                      October\n",
      "    Week number of the year:            40\n",
      "    Weekday of the week:                3\n",
      "    Day of year:                        277\n",
      "    Day of the month :                  03\n",
      "    Day of week:                        Wednesday\n",
      "\n",
      "276052\n",
      "tar -xvzf psutil-0.5.0.tar.gz‌​\n",
      "cd psutil-0.5.0\n",
      "sudo python setup.py install\n",
      "\n",
      "276052\n",
      "from __future__ import print_function\n",
      "import psutil\n",
      "print(psutil.__versi‌​on__)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yinpengcheng/venvs/code_mining/lib/python2.7/site-packages/scipy/stats/stats.py:2247: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return (a - mns) / sstd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3939361\n",
      "{ord('!'): None, ord('@'): None, ...}\n",
      "\n",
      "247770\n",
      "/path1        # \"import bar\" causes the line \"print os.getcwd()\" to run\n",
      "/path2/bar.py # then \"print __file__\" runs\n",
      "/path2/bar.py # then the import statement finishes and \"print bar.__file__\" runs\n",
      "\n",
      "1476\n",
      "7     2147483647                        0o177    0b100110111\n",
      "3     79228162514264337593543950336     0o377    0xdeadbeef\n",
      "      100_000_000_000                   0b_1110_0101\n",
      "\n",
      "1476\n",
      "integer      ::=  decinteger | bininteger | octinteger | hexinteger\n",
      "decinteger   ::=  nonzerodigit ([\"_\"] digit)* | \"0\"+ ([\"_\"] \"0\")*\n",
      "bininteger   ::=  \"0\" (\"b\" | \"B\") ([\"_\"] bindigit)+\n",
      "octinteger   ::=  \"0\" (\"o\" | \"O\") ([\"_\"] octdigit)+\n",
      "hexinteger   ::=  \"0\" (\"x\" | \"X\") ([\"_\"] hexdigit)+\n",
      "nonzerodigit ::=  \"1\"...\"9\"\n",
      "digit        ::=  \"0\"...\"9\"\n",
      "bindigit     ::=  \"0\" | \"1\"\n",
      "octdigit     ::=  \"0\"...\"7\"\n",
      "hexdigit     ::=  digit | \"a\"...\"f\" | \"A\"...\"F\"\n",
      "\n",
      "9001509\n",
      "alan: 2\n",
      "bob: 1\n",
      "carl: 40\n",
      "danny: 3\n",
      "\n",
      "2150739\n",
      "2010-12-16 17:22:15\n",
      "20101216T172215\n",
      "\n",
      "1773805\n",
      "a list:\n",
      "- 1\n",
      "- 42\n",
      "- 3.141\n",
      "- 1337\n",
      "- help\n",
      "- €\n",
      "a string: bla\n",
      "another dict:\n",
      "  foo: bar\n",
      "  key: value\n",
      "  the answer: 42\n",
      "\n",
      "2052390\n",
      "    raise RuntimeError('specific message') from error\n",
      "\n",
      "2600191\n",
      "Counter():  [6.360648187146579, 6.613881559699756, 6.392260466851987]\n",
      "count():    [12.885062765334006, 13.045601897769359, 12.87746743077426]\n",
      "\n",
      "627435\n",
      " 17           0 LOAD_GLOBAL              0 (a)\n",
      "              3 LOAD_ATTR                1 (pop)\n",
      "              6 LOAD_GLOBAL              2 (index)\n",
      "              9 CALL_FUNCTION            1\n",
      "             12 POP_TOP             \n",
      "             13 LOAD_CONST               0 (None)\n",
      "             16 RETURN_VALUE        \n",
      "\n",
      "627435\n",
      " 10           0 LOAD_GLOBAL              0 (a)\n",
      "              3 LOAD_GLOBAL              1 (index)\n",
      "              6 DELETE_SUBSCR       # This is the line that deletes the item\n",
      "              7 LOAD_CONST               0 (None)\n",
      "             10 RETURN_VALUE        \n",
      "None\n",
      "\n",
      "627435\n",
      " 24           0 LOAD_GLOBAL              0 (a)\n",
      "              3 LOAD_GLOBAL              1 (index)\n",
      "              6 SLICE+2             \n",
      "              7 LOAD_GLOBAL              0 (a)\n",
      "             10 LOAD_GLOBAL              1 (index)\n",
      "             13 LOAD_CONST               1 (1)\n",
      "             16 BINARY_ADD          \n",
      "             17 SLICE+1             \n",
      "             18 BINARY_ADD          \n",
      "             19 STORE_GLOBAL             0 (a)\n",
      "             22 LOAD_CONST               0 (None)\n",
      "             25 RETURN_VALUE        \n",
      "None\n",
      "\n",
      "2612802\n",
      "original: ['foo', 5, 'baz']\n",
      "slice: ['foo', 5]\n",
      "list(): ['foo', 5]\n",
      "copy: ['foo', 5]\n",
      "deepcopy: ['foo', 1]\n",
      "\n",
      "466345\n",
      "pip install python-dateutil\n",
      "\n",
      "739993\n",
      "(test_env) $ cd /tmp/behave && python setup.py install\n",
      "running install\n",
      "...\n",
      "Installed /private/tmp/test_env/lib/python2.7/site-packages/enum34-1.0-py2.7.egg\n",
      "Finished processing dependencies for behave==1.2.5a1\n",
      "\n",
      "739993\n",
      "(test_env) $ git clone https://github.com/behave/behave.git\n",
      "Cloning into 'behave'...\n",
      "remote: Reusing existing pack: 4350, done.\n",
      "remote: Total 4350 (delta 0), reused 0 (delta 0)\n",
      "Receiving objects: 100% (4350/4350), 1.85 MiB | 418.00 KiB/s, done.\n",
      "Resolving deltas: 100% (2388/2388), done.\n",
      "Checking connectivity... done.\n",
      "\n",
      "739993\n",
      "$ cd /tmp\n",
      "$ virtualenv test_env\n",
      "New python executable in test_env/bin/python\n",
      "Installing setuptools, pip...done.\n",
      "$ source test_env/bin/activate\n",
      "(test_env) $ \n",
      "\n",
      "739993\n",
      "(test_env) $ ls /tmp/behave/setup.py\n",
      "/tmp/behave/setup.py\n",
      "\n",
      "739993\n",
      "pip freeze\n",
      "\n"
     ]
    }
   ],
   "source": [
    "code_X_y = {}\n",
    "for pid, codes in post_list:\n",
    "    #print '!!!!!!!!!!!!', pid\n",
    "    code_X_y[pid] = generate_x_y(pid, codes, pos_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('for (key, value) in d.iteritems():\\n    pass',\n",
       "  'for (key, value) in d.iteritems():\\n    pass',\n",
       "  'pass',\n",
       "  'for key in d:\\n    pass',\n",
       "  'for key in d:\\n    pass',\n",
       "  'pass',\n",
       "  'for (letter, number) in d.items():\\n    pass',\n",
       "  \"for (letter, number) in d.items():\\n    print letter, 'corresponds to', number\",\n",
       "  \"print letter, 'corresponds to', number\",\n",
       "  'for (key, value) in d.items():\\n    pass',\n",
       "  'for (key, value) in d.items():\\n    pass',\n",
       "  'pass',\n",
       "  'd.items()',\n",
       "  'for (letter, number) in d.items():\\n    pass',\n",
       "  \"for (letter, number) in d.items():\\n    print '{0} corresponds to {1}'.format(letter, number)\",\n",
       "  \"print '{0} corresponds to {1}'.format(letter, number)\",\n",
       "  'for (k, v) in d.items():\\n    pass',\n",
       "  \"for (k, v) in d.items():\\n    print k, 'corresponds to', v\",\n",
       "  \"print k, 'corresponds to', v\",\n",
       "  \"d = {'x': 1, 'y': 2, 'z': 3, }\",\n",
       "  'd.keys()',\n",
       "  'list(d)\\nd.keys()',\n",
       "  'list(d)',\n",
       "  \"d = {'x': 1, 'y': 2, 'z': 3, }\\nlist(d)\",\n",
       "  \"d = {'x': 1, 'y': 2, 'z': 3, }\\nlist(d)\\nd.keys()\"),\n",
       " array([[  1.66899812e+00,   2.30717888e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.30717888e+00,   0.00000000e+00,  -6.97026470e-01,\n",
       "          -7.09930439e-01,  -6.97026470e-01],\n",
       "        [  1.66899812e+00,   2.30717888e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.30717888e+00,   0.00000000e+00,  -6.97026470e-01,\n",
       "          -7.09930439e-01,  -6.97026470e-01],\n",
       "        [  4.92142264e+00,   2.98834991e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.92142264e+00,   0.00000000e+00,   2.08870302e+00,\n",
       "           1.88642136e+00,   2.08870302e+00],\n",
       "        [  1.66744544e+00,   2.33291836e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.33291836e+00,   0.00000000e+00,  -6.98356348e-01,\n",
       "          -6.11821830e-01,  -6.11821830e-01],\n",
       "        [  1.66744544e+00,   2.33291836e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.33291836e+00,   0.00000000e+00,  -6.98356348e-01,\n",
       "          -6.11821830e-01,  -6.11821830e-01],\n",
       "        [  4.92142264e+00,   2.98834991e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.92142264e+00,   0.00000000e+00,   2.08870302e+00,\n",
       "           1.88642136e+00,   2.08870302e+00],\n",
       "        [  2.10038597e+00,   2.46953354e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.46953354e+00,   0.00000000e+00,  -3.27539078e-01,\n",
       "          -9.10993495e-02,  -9.10993495e-02],\n",
       "        [  2.36178414e+00,   2.53809853e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.53809853e+00,   0.00000000e+00,  -1.03649302e-01,\n",
       "           1.70242984e-01,   1.70242984e-01],\n",
       "        [  4.83769512e+00,   2.97735710e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.83769512e+00,   0.00000000e+00,   2.01698968e+00,\n",
       "           1.84452115e+00,   2.01698968e+00],\n",
       "        [  1.60630457e+00,   2.31826038e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.31826038e+00,   0.00000000e+00,  -7.50724030e-01,\n",
       "          -6.67692171e-01,  -6.67692171e-01],\n",
       "        [  1.60630457e+00,   2.31826038e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.31826038e+00,   0.00000000e+00,  -7.50724030e-01,\n",
       "          -6.67692171e-01,  -6.67692171e-01],\n",
       "        [  4.92142264e+00,   2.98834991e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.92142264e+00,   0.00000000e+00,   2.08870302e+00,\n",
       "           1.88642136e+00,   2.08870302e+00],\n",
       "        [  1.79835973e+00,   2.36521397e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.36521397e+00,   0.00000000e+00,  -5.86227135e-01,\n",
       "          -4.88723875e-01,  -4.88723875e-01],\n",
       "        [  2.10038597e+00,   2.46953354e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.46953354e+00,   0.00000000e+00,  -3.27539078e-01,\n",
       "          -9.10993495e-02,  -9.10993495e-02],\n",
       "        [  2.03427237e+00,   2.60599251e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.60599251e+00,   0.00000000e+00,  -3.84165940e-01,\n",
       "           4.29027714e-01,   4.29027714e-01],\n",
       "        [  2.49881276e+00,   2.96245308e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.96245308e+00,   0.00000000e+00,   1.37168878e-02,\n",
       "           1.78771297e+00,   1.78771297e+00],\n",
       "        [  1.55945145e+00,   2.27961006e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.27961006e+00,   0.00000000e+00,  -7.90854125e-01,\n",
       "          -8.15011754e-01,  -7.90854125e-01],\n",
       "        [  1.63036664e+00,   2.28403358e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.28403358e+00,   0.00000000e+00,  -7.30114658e-01,\n",
       "          -7.98151052e-01,  -7.30114658e-01],\n",
       "        [  4.08438301e+00,   2.60645027e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           4.08438301e+00,   0.00000000e+00,   1.37177140e+00,\n",
       "           4.30772526e-01,   1.37177140e+00],\n",
       "        [  2.10536300e+00,   2.40981274e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "           2.40981274e+00,   0.00000000e+00,  -3.23276208e-01,\n",
       "          -3.18731184e-01,  -3.18731184e-01],\n",
       "        [  1.70321574e+00,   2.36456356e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.36456356e+00,   0.00000000e+00,  -6.67718786e-01,\n",
       "          -4.91202962e-01,  -4.91202962e-01],\n",
       "        [  2.48285325e+00,   2.36050072e+00,   1.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.48285325e+00,   0.00000000e+00,   4.74319274e-05,\n",
       "          -5.06688898e-01,   4.74319274e-05],\n",
       "        [  2.19901911e+00,   2.27967968e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "           2.27967968e+00,   0.00000000e+00,  -2.43058942e-01,\n",
       "          -8.14746397e-01,  -2.43058942e-01],\n",
       "        [  1.90403681e+00,   2.24887295e+00,   0.00000000e+00,\n",
       "           0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "           2.24887295e+00,   0.00000000e+00,  -4.95713812e-01,\n",
       "          -9.32169350e-01,  -4.95713812e-01],\n",
       "        [  2.01979762e+00,   2.23238144e+00,   1.00000000e+00,\n",
       "           1.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "           2.23238144e+00,   0.00000000e+00,  -3.96563687e-01,\n",
       "          -9.95028391e-01,  -3.96563687e-01]]),\n",
       " array([ True,  True, False, False, False, False, False, False, False,\n",
       "         True,  True, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False], dtype=bool))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_X_y[3294889]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splite data into traning set and testing set\n",
    "train, test = next(KFold(n_splits=5).split(post_list))\n",
    "train_X, train_y, train_pid, train_code = [], [], [], []\n",
    "for i in train:\n",
    "    pid = post_list[i][0]\n",
    "    for code, x, y in zip(*code_X_y[pid]):\n",
    "        train_X.append(x)\n",
    "        train_y.append(y)\n",
    "        train_pid.append(pid)\n",
    "        train_code.append(code)\n",
    "train_X = np.array(train_X)\n",
    "train_X[np.isnan(train_X)] = 0.\n",
    "test_X, test_y, test_pid, test_code = [], [], [], []\n",
    "for i in test:\n",
    "    pid = post_list[i][0]\n",
    "    for code, x, y in zip(*code_X_y[pid]):\n",
    "        test_X.append(x)\n",
    "        test_y.append(y)\n",
    "        test_pid.append(pid)\n",
    "        test_code.append(code)\n",
    "test_X = np.array(test_X)\n",
    "test_X[np.isnan(test_X)] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#normalize features\n",
    "#normalizer = preprocessing.Normalizer().fit(train_X)\n",
    "#train_X = normalizer.transform(train_X) \n",
    "#test_X = normalizer.transform(test_X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "#classifier = SVC(probability=True, C=0.5, class_weight={1: sum(train_y) * 1.0 / (len(train_y) - sum(train_y))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.95910456 -1.03782901  1.48421566  0.90610469 -0.41933641 -0.611432\n",
      "   0.92160235 -2.74452963 -0.2971079  -0.29009164  0.19726764]]\n",
      "[-1.63596419]\n"
     ]
    }
   ],
   "source": [
    "#using all features\n",
    "full_feature_samples = []\n",
    "full_feature_train_X = train_X[:, :]\n",
    "full_feature_test_X = test_X[:, :]\n",
    "\n",
    "full_feature_clf = classifier.fit(full_feature_train_X, train_y)\n",
    "pickle.dump(full_feature_clf, open('full_feature_clf.p', 'wb'))\n",
    "#clf = pickle.load(open('full_feature_clf.p', 'rb'))\n",
    "predict_y = full_feature_clf.predict(full_feature_test_X)\n",
    "probas_ = full_feature_clf.predict_proba(full_feature_test_X)\n",
    "print full_feature_clf.coef_\n",
    "print full_feature_clf.intercept_\n",
    "#print 'recall', recall_score(test_y, predict_y)\n",
    "#print 'precision', precision_score(test_y, predict_y)\n",
    "#print 'f1', f1_score(test_y, predict_y)\n",
    "for label, p, pid, code, x in zip(predict_y, probas_, test_pid, test_code, full_feature_test_X):\n",
    "    full_feature_samples.append((p, pid, intents[pid], code, x, is_annotated(code, pos_set[pid])))\n",
    "full_feature_samples = sorted(full_feature_samples, key=lambda x:-x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.23222513 -1.5391621   1.28656335 -0.11241168 -0.18867102  0.10230056]]\n",
      "[-0.34093924]\n"
     ]
    }
   ],
   "source": [
    "#using nn features\n",
    "semi_feature_selector = np.array([0,1,6,8,9,10])\n",
    "semi_feature_samples = []\n",
    "semi_feature_train_X = train_X[:, semi_feature_selector]\n",
    "semi_feature_test_X = test_X[:, semi_feature_selector]\n",
    "\n",
    "semi_feature_clf = classifier.fit(semi_feature_train_X, train_y)\n",
    "print semi_feature_clf.coef_\n",
    "print semi_feature_clf.intercept_\n",
    "pickle.dump(semi_feature_clf, open('semi_feature_clf.p', 'wb'))\n",
    "#clf = pickle.load(open('semi_feature_clf.p', 'rb'))\n",
    "predict_y = semi_feature_clf.predict(semi_feature_test_X)\n",
    "probas_ = semi_feature_clf.predict_proba(semi_feature_test_X)\n",
    "#print 'recall', recall_score(test_y, predict_y)\n",
    "#print 'precision', precision_score(test_y, predict_y)\n",
    "#print 'f1', f1_score(test_y, predict_y)\n",
    "for label, p, pid, code, x in zip(predict_y, probas_, test_pid, test_code, semi_feature_test_X):\n",
    "    semi_feature_samples.append((p, pid, intents[pid], code, x, is_annotated(code, pos_set[pid])))\n",
    "semi_feature_samples = sorted(semi_feature_samples, key=lambda x:-x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.67441693  1.07918773 -0.39924452 -1.18500779 -2.48789433]]\n",
      "[-3.90009165]\n"
     ]
    }
   ],
   "source": [
    "#using eng features\n",
    "bin_feature_selector = np.array([2,3,4,5,7])\n",
    "bin_feature_samples = []\n",
    "bin_feature_train_X = train_X[:, bin_feature_selector]\n",
    "bin_feature_test_X = test_X[:, bin_feature_selector]\n",
    "\n",
    "bin_feature_clf = classifier.fit(bin_feature_train_X, train_y)\n",
    "print bin_feature_clf.coef_\n",
    "print bin_feature_clf.intercept_\n",
    "pickle.dump(bin_feature_clf, open('bin_feature_clf.p', 'wb'))\n",
    "#clf = pickle.load(open('bin_feature_clf.p', 'rb'))\n",
    "predict_y = bin_feature_clf.predict(bin_feature_test_X)\n",
    "probas_ = bin_feature_clf.predict_proba(bin_feature_test_X)\n",
    "#print 'recall', recall_score(test_y, predict_y)\n",
    "#print 'precision', precision_score(test_y, predict_y)\n",
    "#print 'f1', f1_score(test_y, predict_y)\n",
    "for label, p, pid, code, x in zip(predict_y, probas_, test_pid, test_code, bin_feature_test_X):\n",
    "    bin_feature_samples.append((p, pid, intents[pid], code, x, is_annotated(code, pos_set[pid])))\n",
    "bin_feature_samples = sorted(bin_feature_samples, key=lambda x:-x[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#baseline approach\n",
    "baseline_samples = []\n",
    "for tidx in test:\n",
    "    pid = post_list[tidx][0]\n",
    "    if pid in baseline:\n",
    "        try:\n",
    "            code = normalize_code(baseline[pid])\n",
    "            baseline_samples.append((pid, intents[pid], code, is_annotated(code, pos_set[pid])))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random selection\n",
    "random_samples = []\n",
    "random_batch = zip(test_pid, test_code)\n",
    "shuffle(random_batch)\n",
    "random_pid, random_code = zip(*random_batch)\n",
    "for pid, code in random_batch:\n",
    "    random_samples.append((pid, intents[pid], code, is_annotated(code, pos_set[pid])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump((full_feature_samples, semi_feature_samples, bin_feature_samples, baseline_samples, random_samples), open('samples.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
